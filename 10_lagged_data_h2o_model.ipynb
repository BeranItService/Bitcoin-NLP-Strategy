{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H2O Models on lagged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Loading the data\n",
    "data = pd.read_csv(\"Data/20180920_mastertable.csv\")\n",
    "\n",
    "# save columns that we do not scale\n",
    "invest = data.invest\n",
    "date = data.date\n",
    "\n",
    "# drop the first row\n",
    "data = data.dropna()\n",
    "\n",
    "# scale the data\n",
    "data_scaled = data.drop([\"date\",\"Unnamed: 0\",\"invest\"], axis=1)\n",
    "\n",
    "# save column names\n",
    "cols = data_scaled.columns\n",
    "\n",
    "# scaling and bring back to pandas\n",
    "data_scaled = preprocessing.scale(data_scaled)\n",
    "data_scaled = pd.DataFrame(data_scaled)\n",
    "\n",
    "# attaching the unscaled data and column names\n",
    "data_scaled.columns = cols\n",
    "data_scaled[\"invest\"] = invest\n",
    "data_scaled[\"date\"] = date\n",
    "\n",
    "# saving as data\n",
    "data = data_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "data = pd.read_csv(\"Data/20180920_mastertable.csv\")\n",
    "for lines in range(4):\n",
    "        data[\"lag_return_day\"+str(lines+1)]=data[\"return_day+1\"].shift(lines+1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we add a 12 day lag based on academic papers for all the columns\n",
    "for lines in range(12):\n",
    "        data[\"lag_return_day\"+str(lines+1)]=data[\"return_day+1\"].shift(lines+1)\n",
    "        data[\"lag_close_day\"+str(lines+1)]=data[\"close\"].shift(lines+1)\n",
    "        data[\"lag_volume_day\"+str(lines+1)]=data[\"volume\"].shift(lines+1)\n",
    "        data[\"lag_googletrends_buy_sell_day\"+str(lines+1)]=data[\"googletrends_buy_sell\"].shift(lines+1)\n",
    "        data[\"lag_Tweets (#)\"+str(lines+1)]=data[\"Tweets (#)\"].shift(lines+1)\n",
    "        data[\"lag_Active Influencers (#)\"+str(lines+1)]=data[\"Active Influencers (#)\"].shift(lines+1)\n",
    "        data[\"lag_Twitter Average SA\"+str(lines+1)]=data[\"Twitter Average SA\"].shift(lines+1)\n",
    "        data[\"lag_Forum SA Merit (weighted)\"+str(lines+1)]=data[\"Forum SA Merit (weighted)\"].shift(lines+1)\n",
    "        data[\"lag_Reddit Comments (#)\"+str(lines+1)]=data[\"Reddit Comments (#)\"].shift(lines+1)\n",
    "        data[\"lag_Reddit Average SA\"+str(lines+1)]=data[\"Reddit Average SA\"].shift(lines+1)\n",
    "        data[\"lag_volatility_14\"+str(lines+1)]=data[\"volatility_14\"].shift(lines+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We drop the return day+1 data since the dependent variable is made with this column\n",
    "data = data.drop([\"return_day+1\",\"lag_return_day1\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>3 hours 5 mins</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>Europe/Amsterdam</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.20.0.7</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>19 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>Daniel</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>1.303 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.6 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O cluster uptime:         3 hours 5 mins\n",
       "H2O cluster timezone:       Europe/Amsterdam\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.20.0.7\n",
       "H2O cluster version age:    19 days\n",
       "H2O cluster name:           Daniel\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    1.303 Gb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  4\n",
       "H2O cluster status:         locked, healthy\n",
       "H2O connection url:         http://localhost:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.6 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Here we initialize h2o\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "#Here we make the training, validation and testing set\n",
    "#We leave 1 day inbetween due to the autocorrelation\n",
    "train = data[0:260].dropna()\n",
    "validation = data[262:300]\n",
    "test = data[302:]\n",
    "#We convert the train, test and validation set to h2o dataframe\n",
    "train = h2o.H2OFrame(train)\n",
    "validation = h2o.H2OFrame(validation)\n",
    "test = h2o.H2OFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify the columns on which we want to regres\n",
    "x = train.columns\n",
    "y = \"invest\"\n",
    "x.remove(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |█████████████████████████"
     ]
    }
   ],
   "source": [
    "# Run AutoML for 120 seconds\n",
    "aml = H2OAutoML(max_runtime_secs = 120,seed = 12)\n",
    "aml.train(x = x, y = y,\n",
    "          training_frame = train,\n",
    "          validation_frame = validation\n",
    "         )\n",
    "# View the AutoML Leaderboard\n",
    "lb = aml.leaderboard\n",
    "lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the best model to predict our test set and convert it to pandas\n",
    "preds = aml.leader.predict(test)\n",
    "predictions = preds.as_data_frame(use_pandas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we evaluate the model\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "test_df = test.as_data_frame(use_pandas=True)\n",
    "test_df\n",
    "y_test = test_df[\"invest\"]\n",
    "predictions = predictions.values[:,2]\n",
    "predictions\n",
    "sklearn.metrics.roc_auc_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(predictions)\n",
    "output.to_csv(\"Data/model_lagged_predictions_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
